{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6157dcda-6514-488b-804b-75690844fb08",
   "metadata": {},
   "source": [
    "# Developing test-cases for SRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3256bb-a1ff-486f-9e40-06deab86826c",
   "metadata": {},
   "source": [
    "For the evaluation of the test-cases, the necessary test datasets are created. The test datasets are stored in the data directory. The following test-cases are considered here: \n",
    "* Subject-switching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36429c37-8924-4fba-b415-108859f69835",
   "metadata": {},
   "source": [
    "First, the needed packages are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a70da51-cde7-4121-baf3-db6c671897e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c54bc-b381-44c2-a71a-218767a71411",
   "metadata": {},
   "source": [
    "## Passive-voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d3b727-566d-4bd3-9d2d-c98d0d9dad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['letter', 'journal', 'book', 'manual', 'guide', 'novel', 'diary', 'story']\n",
    "verbs_pas = ['made', 'created',  'written', 'drafted', 'reported', 'printed']\n",
    "verbs_act = ['made', 'created', 'wrote', 'drafted', 'reported', 'printed']\n",
    "subjects = ['writer', 'author', 'novelist', 'creator']\n",
    "\n",
    "def generate_passive_voice_instances(objects, verbs, subjects):\n",
    "    \"\"\"\n",
    "    Generates test-instances for the passive voice.\n",
    "        E.g. 'The painting was painted by the artist.' with corresponding\n",
    "        labels: [\"B-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"O\"]\n",
    "    \"\"\"\n",
    "    active_sentences = [f'The {subj} {verb} the {obj}.' for obj in objects for verb in verbs_act for subj in subjects]  \n",
    "    passive_sentences = [f'The {obj} was {verb} by the {subj}.' for obj in objects for verb in verbs_pas for subj in subjects]  \n",
    "\n",
    "    #passive_voice_labels =  ['B-ARG1','I-ARG1','O','O','O','B-ARG0','I-ARG0','O']\n",
    "    \n",
    "    data = []\n",
    "    for i, sentence in enumerate(passive_sentences):\n",
    "        tokenized_pas_sent = WordPunctTokenizer().tokenize(sentence)\n",
    "        tokenized_act_sent = WordPunctTokenizer().tokenize(active_sentences[i])\n",
    "        instance = {'capability': 'passive_voice', \n",
    "                    'test_type': 'MFT',\n",
    "                    'test_case': (sentence, active_sentences[i]),\n",
    "                    'target': (tokenized_pas_sent[1], tokenized_act_sent[-2]),\n",
    "                    'label': \"I-ARG1\"}\n",
    "        data.append(instance)\n",
    "        \n",
    "    with open('test_instances/passive_voice.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "generate_passive_voice_instances(objects, verbs, subjects)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606b44a-5526-4a08-83ad-b035e09151fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59be1bc6-d7d0-476f-bd41-991c15333ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['girl', 'gurl', 'gril', 'gilr', 'giirl', 'gil']\n",
    "verbs = ['runs', 'run', 'ruuns', 'rans']\n",
    "subjects = ['mommy', 'mummy', 'mommie', 'momy', 'mumy']\n",
    "\n",
    "def generate_robustness_instances(objects, verbs, subjects):\n",
    "    \"\"\"\n",
    "    Generates test-instances for testing robustness.\n",
    "        E.g. 'The girl runs to mommy.', with corresponding\n",
    "        labels: [\"B-ARG0\", \"I-ARG0\", \"O\", \"O\", \"ARG1\", \"O\"]\n",
    "    \"\"\"\n",
    "    correct_sentence = \"The girl runs to mommy.\"\n",
    "    tokenized_corr_sentence = WordPunctTokenizer().tokenize(correct_sentence)\n",
    "    \n",
    "    robustness_sentences = [f'The {obj} {verb} to {subj}.' for obj in objects for verb in verbs for subj in subjects]\n",
    "    robustness_labels =  ['B-ARG0', 'I-ARG0', 'O', 'O', 'ARG1', 'O']\n",
    "    \n",
    "    data = []\n",
    "    for i, sentence in enumerate(robustness_sentences):\n",
    "        tokenized_robu_sentence = WordPunctTokenizer().tokenize(sentence)\n",
    "        instance = {'capability': 'robustness', \n",
    "                    'test_type': 'INV',\n",
    "                    'test_case': (sentence, correct_sentence),\n",
    "                    'target': (\"girl\", tokenized_robu_sentence[1]),\n",
    "                    'label': \"I-ARG0\"}\n",
    "        data.append(instance)\n",
    "        \n",
    "    with open('test_instances/robustness.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "generate_robustness_instances(objects, verbs, subjects)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a3368-fd21-4d51-81a6-1ccc7d8a68c0",
   "metadata": {},
   "source": [
    "## Subject-object switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b280c7bc-6ee1-4bee-9f94-9c0bacb3ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['Ann', 'Rose', 'Noah', 'Coco']\n",
    "verbs = ['loves', 'likes', 'hates', 'despises', 'hugs']\n",
    "subjects = ['Pete', 'Frank', 'Marie', 'Elise']\n",
    "\n",
    "def generate_switched_instances(objects, verbs, subjects):\n",
    "    \"\"\"\n",
    "    Generates test-instances for testing subject-object switching.\n",
    "        E.g. 'Ann loves Pete' and 'Pete loves Ann', with corresponding\n",
    "        labels: [\"B-ARG0\", \"B-V\", \"B-ARG1\", \"O\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = [f'{obj} {verb} {subj}.' for obj in objects for verb in verbs for subj in subjects]    \n",
    "    switched_sentences = [f'{subj} {verb} {obj}.' for obj in objects for verb in verbs for subj in subjects]    \n",
    "    switched_labels =  [\"B-ARG0\", \"B-V\", \"B-ARG1\", \"O\"]\n",
    "\n",
    "    data = []\n",
    "    for i, sentence in enumerate(switched_sentences):\n",
    "        tokenized_sentence = WordPunctTokenizer().tokenize(sentences[i])\n",
    "        tokenized_swi_sentence = WordPunctTokenizer().tokenize(sentence)\n",
    "        instance = {'capability': 'subj-obj-switching', \n",
    "                    'test_type': 'INV',\n",
    "                    'test_case': (sentence, sentences[i]),\n",
    "                    'label': switched_labels}\n",
    "        data.append(instance)\n",
    "        \n",
    "    with open('test_instances/switching.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "generate_switched_instances(objects, verbs, subjects)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8ed42-b06f-4b93-b46d-341825b3b587",
   "metadata": {},
   "source": [
    "## Caused motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1c6f8f-7b6a-4baf-8738-f9614e5886d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_sentences = ['The wind blew.', \n",
    "                   'The cat knocked.',\n",
    "                   'The chef rolled.',\n",
    "                   'The child dragged.',\n",
    "                   'The hammer struck.',\n",
    "                   'The man pushed.',\n",
    "                   'The ball bounced.',\n",
    "                   'The girl threw.',\n",
    "                   'The storm blew.',\n",
    "                   'The skater glided.', \n",
    "                   'The boat floated.',\n",
    "                   'The boy kicked.', \n",
    "                   'The bulldozer pushed.',\n",
    "                   'The waiter served.', \n",
    "                   'The guitarist strummed.',\n",
    "                   'The farmer drove.', \n",
    "                   'The rocket launched.',\n",
    "                   'The dog chased.',\n",
    "                   'The child pushed.',\n",
    "                   'The dog chased.',\n",
    "                   'The train pulled.',\n",
    "                   'The bird flew.',\n",
    "                   'The boat drifted.',\n",
    "                   'The man kicked.',\n",
    "                   'The wave crashed.',\n",
    "                   'The car hit.',\n",
    "                   'The arrow pierced.',\n",
    "                   'The skater glided.',\n",
    "                   'The rock rolled.',\n",
    "                   'The woman threw.',\n",
    "                   'The butterfly fluttered.',\n",
    "                   'The leaf fell.',\n",
    "                   'The boy kicked.',\n",
    "                   'The hand waved.',\n",
    "                   'The balloon floated.',\n",
    "                   'The plane soared.',\n",
    "                   'The horse galloped.',\n",
    "                   'The snake slithered.',\n",
    "                   'The cat jumped.',\n",
    "                   'The fire burned.',\n",
    "                   'The arrow flew.',\n",
    "                   'The water flowed.',\n",
    "                   'The wind howled.',\n",
    "                   'The bird chirped.',    \n",
    "                   'The whale swam.',\n",
    "                   'The ice cracked.',    \n",
    "                   'The bike rode.',\n",
    "                   'The door slammed.',    \n",
    "                   'The frog leaped.',\n",
    "                   'The monkey climbed.']\n",
    "                    \n",
    "                \n",
    "def generate_motion_instances(motion_sentences):\n",
    "    \"\"\"\n",
    "    Generates test-instances for testing caused motion.\n",
    "        E.g. 'The wind blew', with corresponding\n",
    "        labels: [\"ARG0\", \"V\", \"ARG1\", \"O\"]\n",
    "    \"\"\"   \n",
    "    motion_sentences = motion_sentences \n",
    "    motion_labels =  [\"B-ARG1\", \"I-ARG1\", \"B-V\", \"O\"]\n",
    "    \n",
    "    data = []\n",
    "    for sentence in motion_sentences:\n",
    "        instance = {'capability': 'caused-motion', \n",
    "                    'test_type': 'MFT',\n",
    "                    'test_case': sentence,\n",
    "                    'label': motion_labels}\n",
    "        data.append(instance)\n",
    "        \n",
    "    with open('test_instances/caused_motion.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "generate_motion_instances(motion_sentences)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
