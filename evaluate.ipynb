{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4c33a8-2b37-444a-9296-b3a1b963c392",
   "metadata": {},
   "source": [
    "# Evaluate testcases on models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb94de84-eb48-46fc-acb6-7f51a3956c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10cd0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\romer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "from allennlp_models.pretrained import load_predictor\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2003cfb7-7f41-47bc-95c4-58bc257cd8ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\romer\\AppData\\Local\\Temp\\tmpwn_7krqf\\config.json as plain json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f96f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\romer\\AppData\\Local\\Temp\\tmpnu48a7ow\\config.json as plain json\n"
     ]
    }
   ],
   "source": [
    "bilstm = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a2c86d-60bc-4b99-8569-1c63af16c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_testset(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a988f799-7148-4705-91ac-2fff355d12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the datasets\n",
    "passive_voice = load_testset('test_instances/passive_voice.json')\n",
    "robustness = load_testset('test_instances/robustness.json')\n",
    "switching = load_testset('test_instances/switching.json')\n",
    "caused_motion = load_testset('test_instances/caused_motion.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc9b06",
   "metadata": {},
   "source": [
    "## Evaluation capability of Passive Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "041b151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_voice(models, data):\n",
    "    for model_name in models: \n",
    "        if model_name == \"BERT\":\n",
    "            model = bert\n",
    "        if model_name == \"BiLSTM\":\n",
    "            model = bilstm\n",
    "            \n",
    "        print(f\"Evaluation of capability: passive voice, using model: {model_name}.\\n\")\n",
    "        \n",
    "        pred_labels_passive = []\n",
    "        true_labels_passive = []\n",
    "        pred_labels_active = []\n",
    "        true_labels_active = []\n",
    "        total, failures = 0, 0\n",
    "        failed_sentences = []\n",
    "        passive_fails, active_fails = [], []\n",
    "        \n",
    "        for sentence in data:\n",
    "            passive = sentence['test_case'][0]\n",
    "            active = sentence['test_case'][1]\n",
    "            true_passive_label = sentence['label']\n",
    "            true_active_label = sentence['label']\n",
    "\n",
    "            pred_passive = model.predict(passive)\n",
    "            pred_active = model.predict(active)\n",
    "\n",
    "            pred_passive_label = pred_passive['verbs'][1]['tags'][1]\n",
    "            pred_active_label = pred_active['verbs'][0]['tags'][4]\n",
    "\n",
    "            total += 2\n",
    "\n",
    "            if pred_passive_label != true_passive_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"P\", passive, true_passive_label, pred_passive_label])\n",
    "            if pred_active_label != true_active_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"A\", active, true_active_label, pred_active_label])\n",
    "\n",
    "            pred_labels_passive.append(pred_passive_label)\n",
    "            true_labels_passive.append(true_passive_label)\n",
    "            pred_labels_active.append(pred_active_label)\n",
    "            true_labels_active.append(true_active_label)\n",
    "        \n",
    "        percentage = (failures/total)*100\n",
    "        for sentence in failed_sentences:\n",
    "            if sentence[0] == \"P\":\n",
    "                passive_fails.append(sentence)\n",
    "            else:\n",
    "                active_fails.append(sentence)\n",
    "        \n",
    "        print(f\"Number of test cases: {total}.\")\n",
    "        print(f\"Failures: {failures} ({percentage:.3f}%).\\n\")\n",
    "        # Evaluate performance on passive voice test cases\n",
    "        if len(passive_fails) > 0:\n",
    "            print(f\"--- Passive sentences test cases ---\")\n",
    "            print(f\"Examples of failures\")\n",
    "            if len(passive_fails) < 4:\n",
    "                for i in range(0,len(passive_fails)):\n",
    "                    print(f\"Sentence: {passive_fails[i][1]}\")\n",
    "                    print(f\"True labels: {passive_fails[i][2]}\")\n",
    "                    print(f\"Predicted labels: {passive_fails[i][3]}\\n\")\n",
    "            else:\n",
    "                for i in range(0,4):\n",
    "                    print(f\"Sentence: {passive_fails[i][1]}\")\n",
    "                    print(f\"True labels: {passive_fails[i][2]}\")\n",
    "                    print(f\"Predicted labels: {passive_fails[i][3]}\\n\")\n",
    "\n",
    "\n",
    "        # Evaluate performance on active voice test cases\n",
    "        if len(active_fails) > 0:\n",
    "            print(f\"--- Passive sentences test cases ---\")\n",
    "            print(f\"Examples of failures\")\n",
    "            if len(active_fails) < 4:\n",
    "                for i in range(0,len(active_fails)):\n",
    "                    print(f\"Sentence: {active_fails[i][1]}\")\n",
    "                    print(f\"True labels: {active_fails[i][2]}\")\n",
    "                    print(f\"Predicted labels: {active_fails[i][3]}\\n\")\n",
    "            else:\n",
    "                for i in range(0,4):\n",
    "                    print(f\"Sentence: {active_fails[i][1]}\")\n",
    "                    print(f\"True labels: {active_fails[i][2]}\")\n",
    "                    print(f\"Predicted labels: {active_fails[i][3]}\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34a13a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of capability: passive voice, using model: BERT.\n",
      "\n",
      "Number of test cases: 384.\n",
      "Failures: 2 (0.521%).\n",
      "\n",
      "--- Passive sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The writer wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The author wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARGM-LOC\n",
      "\n",
      "Evaluation of capability: passive voice, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 384.\n",
      "Failures: 4 (1.042%).\n",
      "\n",
      "--- Passive sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The writer wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The author wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The novelist wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The creator wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_voice([\"BERT\", \"BiLSTM\"], passive_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec17d85",
   "metadata": {},
   "source": [
    "## Evaluation capability of Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5619699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(models, data):\n",
    "    for model_name in models: \n",
    "        if model_name == \"BERT\":\n",
    "            model = bert\n",
    "        if model_name == \"BiLSTM\":\n",
    "            model = bilstm\n",
    "        \n",
    "        print(f\"Evaluation of capability: robustness, using model: {model_name}.\\n\")\n",
    "        \n",
    "        pred_labels_correct = []\n",
    "        true_labels_correct = []\n",
    "        pred_labels_typos = []\n",
    "        true_labels_typos = []\n",
    "        failed_sentences = []\n",
    "        total, failures = 0, 0\n",
    "        \n",
    "        correct_fails, typos_fails = [], []\n",
    "        \n",
    "        for sentence in data:\n",
    "            correct = sentence['test_case'][0]\n",
    "            typos = sentence['test_case'][1]\n",
    "            true_correct_label = sentence['label']\n",
    "            true_typo_label = sentence['label']\n",
    "\n",
    "            pred_correct = model.predict(correct)\n",
    "            pred_typo = model.predict(typos)\n",
    "            \n",
    "            if len(pred_correct['verbs']) >0: \n",
    "                pred_correct_label = pred_correct['verbs'][0]['tags'][1]\n",
    "            else: \n",
    "                pred_correct_label = 0\n",
    "                \n",
    "            if len(pred_typo['verbs']) >0:\n",
    "                pred_typo_label = pred_typo['verbs'][0]['tags'][1]\n",
    "            else:\n",
    "                pred_typo_label = 0\n",
    "            \n",
    "            total += 2\n",
    "            \n",
    "            if pred_correct_label != true_correct_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"C\", correct, true_correct_label, pred_correct_label])\n",
    "            if pred_typo_label != true_typo_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"T\", typos, true_typo_label, pred_typo_label])\n",
    "\n",
    "            pred_labels_correct.append(pred_correct_label)\n",
    "            true_labels_correct.append(true_correct_label)\n",
    "            pred_labels_typos.append(pred_typo_label)\n",
    "            true_labels_typos.append(true_typo_label)\n",
    "        \n",
    "        percentage = (failures/total)*100\n",
    "        for sentence in failed_sentences:\n",
    "            if sentence[0] == \"C\":\n",
    "                correct_fails.append(sentence)\n",
    "            else:\n",
    "                typos_fails.append(sentence)\n",
    "\n",
    "        \n",
    "        print(f\"Number of test cases: {total}.\")\n",
    "        print(f\"Failures: {failures} ({percentage:.3f}%).\\n\")\n",
    "        # Evaluate performance on correct test cases\n",
    "        if len(correct_fails) > 1:\n",
    "            print(f\"--- Normal sentences test cases ---\")\n",
    "            print(f\"Examples of failures\")\n",
    "            for i in range(0,4):\n",
    "                print(f\"Sentence: {correct_fails[i][1]}\")\n",
    "                print(f\"True labels: {correct_fails[i][2]}\")\n",
    "                print(f\"Predicted labels: {correct_fails[i][3]}\\n\")\n",
    "\n",
    "        # Evaluate performance on typo test cases\n",
    "        if len(typos_fails) > 1:\n",
    "            print(f\"--- Typo sentences test cases ---\")\n",
    "            print(f\"Examples of failures\")\n",
    "            for i in range(0,4):\n",
    "                print(f\"Sentence: {typos_fails[i][1]}\")\n",
    "                print(f\"True labels: {typos_fails[i][2]}\")\n",
    "                print(f\"Predicted labels: {typos_fails[i][3]}\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95766c2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of capability: robustness, using model: BERT.\n",
      "\n",
      "Number of test cases: 240.\n",
      "Failures: 56 (23.333%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The gurl ruuns to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to mummy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to mommie.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to momy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Evaluation of capability: robustness, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 240.\n",
      "Failures: 175 (72.917%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mummy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommie.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to momy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "--- Typo sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness([\"BERT\", \"BiLSTM\"], robustness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb468c",
   "metadata": {},
   "source": [
    "## Evaluation capability of Switching Object and Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb5ac5f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_switching(models, data):\n",
    "    for model_name in models: \n",
    "        if model_name == \"BERT\":\n",
    "            model = bert\n",
    "        if model_name == \"BiLSTM\":\n",
    "            model = bilstm\n",
    "            \n",
    "        print(f\"Evaluation of capability: subject-object switching, using model: {model_name}.\\n\")\n",
    "            \n",
    "        pred_labels_normal = []\n",
    "        true_labels_normal = []\n",
    "        pred_labels_switched = []\n",
    "        true_labels_switched = []\n",
    "        failed_sentences = []\n",
    "        total, failures = 0, 0\n",
    "        normal_fails, switched_fails = [], []\n",
    "\n",
    "        for sentence in switching:\n",
    "            normal = sentence['test_case'][0]\n",
    "            switched = sentence['test_case'][1]\n",
    "            true_normal_label = sentence['label']\n",
    "            true_switched_label = sentence['label']\n",
    "            pred_normal = model.predict(normal)\n",
    "            pred_switched = model.predict(switched)\n",
    "\n",
    "            if len(pred_normal['verbs']) > 0: \n",
    "                pred_normal_label = pred_normal['verbs'][0]['tags']\n",
    "            else: \n",
    "                pred_normal_label = 0\n",
    "\n",
    "            if len(pred_switched['verbs']) > 0:\n",
    "                pred_switched_label = pred_switched['verbs'][0]['tags']\n",
    "            else:\n",
    "                pred_switched_label = 0\n",
    "\n",
    "            total += 2\n",
    "\n",
    "            if pred_normal_label != true_normal_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"N\", normal, true_normal_label, pred_normal_label])\n",
    "            if pred_switched_label != true_switched_label:\n",
    "                failures += 1\n",
    "                failed_sentences.append([\"S\", switched, true_switched_label, pred_switched_label])\n",
    "\n",
    "            pred_labels_normal.append(pred_normal_label)\n",
    "            true_labels_normal.append(true_normal_label)\n",
    "            pred_labels_switched.append(pred_switched_label)\n",
    "            true_labels_switched.append(true_switched_label)\n",
    "\n",
    "        percentage = (failures/total)*100\n",
    "        for sentence in failed_sentences:\n",
    "            if sentence[0] == \"N\":\n",
    "                normal_fails.append(sentence)\n",
    "            else:\n",
    "                switched_fails.append(sentence)\n",
    "\n",
    "        print(f\"Number of test cases: {total}.\")\n",
    "        print(f\"Failures: {failures} ({percentage:.3f}%).\\n\")\n",
    "        # Evaluate performance on normal test cases\n",
    "        print(f\"--- Normal sentences test cases ---\")\n",
    "        print(f\"Examples of failures\")\n",
    "        for i in range(0,4):\n",
    "            print(f\"Sentence: {normal_fails[i][1]}\")\n",
    "            print(f\"True labels: {normal_fails[i][2]}\")\n",
    "            print(f\"Predicted labels: {normal_fails[i][3]}\\n\")\n",
    "\n",
    "        # Evaluate performance on swithced test cases\n",
    "        print(f\"--- Switched sentences test cases ---\")\n",
    "        print(f\"Examples of failures\")\n",
    "        for i in range(0,4):\n",
    "            print(f\"Sentence: {switched_fails[i][1]}\")\n",
    "            print(f\"True labels: {switched_fails[i][2]}\")\n",
    "            print(f\"Predicted labels: {switched_fails[i][3]}\\n\")\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4a67a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of capability: subject-object switching, using model: BERT.\n",
      "\n",
      "Number of test cases: 160.\n",
      "Failures: 33 (20.625%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Elise likes Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Elise hates Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Frank hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Marie hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "--- Switched sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Ann hugs Frank.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Ann hugs Marie.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Ann hugs Elise.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Rose hugs Pete.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Evaluation of capability: subject-object switching, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 160.\n",
      "Failures: 50 (31.250%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Elise likes Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Elise hates Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'B-ARG1', 'B-ARG2', 'O']\n",
      "\n",
      "Sentence: Pete hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARG0', 'B-V', 'B-ARG2', 'O']\n",
      "\n",
      "Sentence: Frank hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "--- Switched sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Ann despises Pete.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['O', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Frank.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Marie.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['O', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Elise.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_switching(['BERT', 'BiLSTM'], switching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca27224",
   "metadata": {},
   "source": [
    "## Evaluation capability of Caused Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e10046a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_caused_motion(models, data):\n",
    "    for model_name in models: \n",
    "        if model_name == \"BERT\":\n",
    "            model = bert\n",
    "        if model_name == \"BiLSTM\":\n",
    "            model = bilstm\n",
    "  \n",
    "        print(f\"Evaluation of capability: caused motion, using model: {model_name}.\\n\")\n",
    "    \n",
    "        pred_labels, true_labels = [], []\n",
    "        failures, total = 0, 0\n",
    "        fails = []\n",
    "        \n",
    "        for sentence in data:\n",
    "            sent = sentence['test_case']\n",
    "            true_label = sentence['label'][1]\n",
    "            pred = model.predict(sent)\n",
    "            if len(pred['verbs']) > 0:\n",
    "                pred_label = pred['verbs'][0]['tags'][1]\n",
    "            else:\n",
    "                pred_label = 0\n",
    "\n",
    "            total += 1\n",
    "    \n",
    "            if pred_label != true_label:\n",
    "                fails.append([sent, true_label, pred_label])\n",
    "                failures += 1\n",
    "\n",
    "            pred_labels.append(pred_label)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        percentage = (failures/total)*100\n",
    "        \n",
    "        print(f\"Number of test cases: {total}.\")\n",
    "        print(f\"Failures: {failures} ({percentage:.3f}%).\\n\")\n",
    "        # Evaluate performance on passive voice test cases\n",
    "\n",
    "        print(f\"--- Test cases ---\")\n",
    "        print(f\"Examples of failures\")\n",
    "        for i in range(0,4):\n",
    "            print(f\"Sentence: {fails[i][0]}\")\n",
    "            print(f\"True labels: {fails[i][1]}\")\n",
    "            print(f\"Predicted labels: {fails[i][2]}\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08180af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of capability: caused motion, using model: BERT.\n",
      "\n",
      "Number of test cases: 50.\n",
      "Failures: 30 (60.000%).\n",
      "\n",
      "--- Test cases ---\n",
      "Examples of failures\n",
      "Sentence: The child dragged.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The hammer struck.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The man pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The girl threw.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Evaluation of capability: caused motion, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 50.\n",
      "Failures: 17 (34.000%).\n",
      "\n",
      "--- Test cases ---\n",
      "Examples of failures\n",
      "Sentence: The hammer struck.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The man pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The girl threw.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The bulldozer pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_caused_motion(['BERT', \"BiLSTM\"], caused_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81c07321",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of capability: passive voice, using model: BERT.\n",
      "\n",
      "Number of test cases: 384.\n",
      "Failures: 2 (0.521%).\n",
      "\n",
      "--- Passive sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The writer wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The author wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARGM-LOC\n",
      "\n",
      "Evaluation of capability: passive voice, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 384.\n",
      "Failures: 4 (1.042%).\n",
      "\n",
      "--- Passive sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The writer wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The author wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The novelist wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The creator wrote the journal.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "\n",
      "\n",
      "Evaluation of capability: robustness, using model: BERT.\n",
      "\n",
      "Number of test cases: 240.\n",
      "Failures: 56 (23.333%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The gurl ruuns to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to mummy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to mommie.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: The gurl ruuns to momy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: 0\n",
      "\n",
      "Evaluation of capability: robustness, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 240.\n",
      "Failures: 175 (72.917%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mummy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommie.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to momy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "--- Typo sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "Sentence: The girl runs to mommy.\n",
      "True labels: I-ARG0\n",
      "Predicted labels: I-ARG1\n",
      "\n",
      "\n",
      "\n",
      "Evaluation of capability: subject-object switching, using model: BERT.\n",
      "\n",
      "Number of test cases: 160.\n",
      "Failures: 33 (20.625%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Elise likes Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Elise hates Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Frank hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Marie hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "--- Switched sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Ann hugs Frank.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Ann hugs Marie.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Ann hugs Elise.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Sentence: Rose hugs Pete.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "Evaluation of capability: subject-object switching, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 160.\n",
      "Failures: 50 (31.250%).\n",
      "\n",
      "--- Normal sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Elise likes Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Elise hates Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-V', 'B-ARG1', 'B-ARG2', 'O']\n",
      "\n",
      "Sentence: Pete hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARG0', 'B-V', 'B-ARG2', 'O']\n",
      "\n",
      "Sentence: Frank hugs Ann.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: 0\n",
      "\n",
      "--- Switched sentences test cases ---\n",
      "Examples of failures\n",
      "Sentence: Ann despises Pete.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['O', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Frank.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Marie.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['O', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "Sentence: Ann despises Elise.\n",
      "True labels: ['B-ARG0', 'B-V', 'B-ARG1', 'O']\n",
      "Predicted labels: ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'O']\n",
      "\n",
      "\n",
      "\n",
      "Evaluation of capability: caused motion, using model: BERT.\n",
      "\n",
      "Number of test cases: 50.\n",
      "Failures: 30 (60.000%).\n",
      "\n",
      "--- Test cases ---\n",
      "Examples of failures\n",
      "Sentence: The child dragged.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The hammer struck.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The man pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The girl threw.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Evaluation of capability: caused motion, using model: BiLSTM.\n",
      "\n",
      "Number of test cases: 50.\n",
      "Failures: 17 (34.000%).\n",
      "\n",
      "--- Test cases ---\n",
      "Examples of failures\n",
      "Sentence: The hammer struck.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG2\n",
      "\n",
      "Sentence: The man pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The girl threw.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "Sentence: The bulldozer pushed.\n",
      "True labels: I-ARG1\n",
      "Predicted labels: I-ARG0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_voice([\"BERT\", \"BiLSTM\"], passive_voice)\n",
    "evaluate_robustness([\"BERT\", \"BiLSTM\"], robustness)\n",
    "evaluate_switching(['BERT', 'BiLSTM'], switching)\n",
    "evaluate_caused_motion(['BERT', \"BiLSTM\"], caused_motion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
